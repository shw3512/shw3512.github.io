%
% Quiz 12 : 2019-07-23 (T)
%
\section{Exercise}

(5 pt) Let $V = \reals^{3}$ be the vector space of $3 \times 1$ matrices with entries in $\reals$, equipped with the usual operations of matrix addition and scalar multiplication. Let
\begin{align*}
v_{1}
=
\begin{bmatrix}
1	\\
0	\\
1
\end{bmatrix}%
,
&&
v_{2}
=
\begin{bmatrix}
2	\\
-1	\\
0
\end{bmatrix}%
,
&&
v_{3}
=
\begin{bmatrix}
1	\\
1	\\
0
\end{bmatrix}%
.
\end{align*}
\begin{enumerate}[label=(\alph*)]
\item\label{itm : Quiz 12 Linear Independence} (2 pt) Row reduce the matrix $\begin{bmatrix}v_{1}&v_{2}&v_{3}\end{bmatrix}$ to show that the set $\{v_{1},v_{2},v_{3}\}$ is linearly independent. \fontHint{Is every column in the row-reduced matrix a pivot column?}
\end{enumerate}

\spaceSolution{2.5in}{% Begin solution.
By definition, the set $\{v_{1},v_{2},v_{3}\}$ is linearly independent if their only linear combination that equals the zero vector is the trivial linear combination with all coefficients equal to $0$:
\begin{align*}
a_{1} v_{1} + a_{2} v_{2} + a_{3} v_{3}
=
0
&&
\Leftrightarrow
&&
\text{all $a_{i} = 0$}.
\end{align*}
This is equivalent to the statement that the corresponding system of linear equations
\begin{align}
\begin{bmatrix}
1	&	2	&	1	\\
0	&	-1	&	1	\\
1	&	0	&	0
\end{bmatrix}
\begin{bmatrix}
a_{1}	\\
a_{2}	\\
a_{3}
\end{bmatrix}
=
\begin{bmatrix}
|	&	|	&	|	\\
v_{1}	&	v_{2}	&	v_{3}	\\
|	&	|	&	|
\end{bmatrix}
\begin{bmatrix}
a_{1}	\\
a_{2}	\\
a_{3}
\end{bmatrix}
=
\begin{bmatrix}
0	\\
0	\\
0
\end{bmatrix}%
\label{eq : Quiz 12 Matrix Equation}
\end{align}
has the unique solution $\transpose{\begin{bmatrix}a_{1}&a_{2}&a_{3}\end{bmatrix}} = \transpose{\begin{bmatrix}0&0&0\end{bmatrix}}$. If we row reduce the augmented matrix associated to this system, we obtain the $3 \times 3$ identity matrix $I$ on the left, and (necessarily --- why?) a column of $0$s in the added column 4. The RREF augmented matrix corresponds to the linear system
\begin{align*}
a_{1}
=
0,
&&
a_{2}
=
0,
&&
a_{3}
=0.
\end{align*}
This shows that if a linear combination of $v_{1},v_{2},v_{3}$ equals the zero vector, then all the coefficients $a_{i}$ are zero. Hence the set $\{v_{1},v_{2},v_{3}\}$ is linearly independent.}% End solution.



\begin{enumerate}[resume,label=(\alph*)]
\item\label{itm : Quiz 12 Determinant} (2 pt) Compute the determinant of the $3 \times 3$ matrix $\begin{bmatrix}v_{1}&v_{2}&v_{3}\end{bmatrix}$. \fontHint{Use expansion by minors along row 3.}
\end{enumerate}

\spaceSolution{1in}{% Begin solution.
We compute
\begin{align*}
\det
\begin{bmatrix}
1	&	2	&	1	\\
0	&	-1	&	1	\\
1	&	0	&	0
\end{bmatrix}
=
(-1)^{3 + 1} (1) \det
\begin{bmatrix}
2	&	1	\\
-1	&	1
\end{bmatrix}
+ 0 + 0
=
(1) (1) (2 - (-1))
=
3.
\end{align*}
}% End solution.



\begin{enumerate}[resume,label=(\alph*)]
\item\label{itm : Quiz 12 Nonzero Determinant} (1 pt) How does our computation in part \ref{itm : Quiz 12 Determinant} give us another solution to part \ref{itm : Quiz 12 Linear Independence}? How is the row-reduction approach in part \ref{itm : Quiz 12 Linear Independence} more general than the determinant approach in part \ref{itm : Quiz 12 Determinant}?
\end{enumerate}

\spaceSolution{1in}{% Begin solution.
In part \ref{itm : Quiz 12 Determinant}, we found that the determinant of $\begin{bmatrix}v_{1}&v_{2}&v_{3}\end{bmatrix}$ is nonzero. Thus there exists a (unique) inverse matrix, $\begin{bmatrix}v_{1}&v_{2}&v_{3}\end{bmatrix}^{-1}$. Left-multiplying both sides of \eqref{eq : Quiz 12 Matrix Equation} by this inverse matrix, we get
\begin{align*}
\begin{bmatrix}
a_{1}	\\
a_{2}	\\
a_{3}
\end{bmatrix}
=
\begin{bmatrix}
|	&	|	&	|	\\
v_{1}	&	v_{2}	&	v_{3}	\\
|	&	|	&	|
\end{bmatrix}
^{-1}
\begin{bmatrix}
0	\\
0	\\
0
\end{bmatrix}
=
\begin{bmatrix}
0	\\
0	\\
0
\end{bmatrix}%
.
\end{align*}
That is, all $a_{i} = 0$, so the set $\{v_{1},v_{2},v_{3}\}$ is linearly independent.

Note that we can apply the row-reduction approach to any number of vectors; this approach says the vectors are linearly independent if and only if every column is a pivot column. The determinant is defined only for square matrices. Thus, the determinant approach works only for $n$ vectors in $\reals^{n}$; this approach says that $n$ vectors in $\reals^{n}$ are linearly independent if and only if the determinant of the corresponding $n \times n$ matrix is nonzero. (Does the order of the vectors in this matrix matter? Why or why not?)}% End solution.



%\begin{enumerate}[resume,label=(\alph*)]
%\item\label{itm : Quiz 12 Span} (2 pt) Does the set $\{v_{1},v_{2},v_{3}\}$ span $V$? Justify. \fontHint{What is the dimension of $V = \reals^{3}$? How many linearly independent vectors are in the set $\{v_{1},v_{2},v_{3}\}$?}
%\end{enumerate}
%
%\spaceSolution{2in}{% Begin solution.
%}% End solution.
%
%
%
%\begin{enumerate}[resume,label=(\alph*)]
%\item\label{itm : Quiz 12 Existence And Uniqueness} (1 pt) Does there exist a linear combination of $v_{1},v_{2},v_{3}$ that equals the vector $\transpose{\begin{bmatrix}0&\pi&e^{-1}\end{bmatrix}}$? If such a linear combination exists, is it unique? \fontHint{You needn't compute anything for this part. Instead, use your results above.}
%\end{enumerate}
%
%\spaceSolution{2in}{% Begin solution.
%}% End solution.