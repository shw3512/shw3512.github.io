%%%%%%%%%%%%%%%%%%%%
%
%	Exam 01 : 2024--03--01 (F)
%
%%%%%%%%%%%%%%%%%%%%



\section{Exercise \ref{sec : e01q1}}
\label{sec : e01q1}

(4 pt) Let $R$ be a commutative ring with a multiplicative identity $1 \neq 0$. An element $a \in R$ is \fontDefWord{nilpotent} if there exists an $n \in \integersPositive$ such that $a^{n} = 0$.
\begin{enumerate}[label=(\alph*)]
\item\label{itm : e01q1a} Let $a \in R$ be nonzero. Prove that if $a$ is nilpotent, then $a$ is a zero divisor.
\item\label{itm : e01q1b} Give an example to show that the converse of \ref{itm : e01q1a} is false.
\item\label{itm : e01q1c} Let $a \in R$ be nilpotent. Prove that $1 - a$ is a unit.
\end{enumerate}

\spaceSolution{6in}{% Begin solution.
Part \ref{itm : e01q1a}: Let $a \in R$ be a nonzero nilpotent element, and let
\begin{align*}
n_{0}
=
\min\{n \in \integersPositive \st a^{n} = 0\}
\end{align*}
By hypothesis, (i) $a$ is nilpotent, so this set is nonempty, and hence $n_{0}$ is well defined (and exists by the well ordering of $\Z$); and (ii) $a$ is nonzero, so $n_{0} \geq 2$. Let $b = a^{n_{0} - 1}$. Then $b \neq 0$, and
\begin{align*}
a b
=
a a^{n_{0} - 1}
=
a^{n_{0}}
=
0
\end{align*}
so $a$ is a zero divisor.

Remark. The definition of zero divisor requires only one of $a b = 0$ or $b a = 0$. In the current setting, we get both, because $R$ is commutative.

Part \ref{itm : e01q1b}: The converse of \ref{itm : e01q1a} is the statement, ``Let $a \in R$ be nonzero. If $a$ is a zero divisor, then $a$ is nilpotent.'' To see that this is false, consider the element $a = 2$ in the ring $R = \Z / (6)$. $2$ is a zero divisor: $2 \times 3 = 0$. However, $2$ is not nilpotent: For all $n \in \integersPositive$, $6 \notDivides 2^{n}$ in $\Z$, hence $2^{n} \neq 0$ in $\Z / (6)$.

Part \ref{itm : e01q1c}: Let $n_{0} \in \integersPositive$ be defined as in our solution to part \ref{itm : e01q1a}, and let
\begin{align*}
b
=
1 + a + \ldots + a^{n_{0} - 1}
\end{align*}
Then% Begin footnote.
\footnote{In the first equality, we use the definition of $b$; in the second, the ring axioms, namely, the left distribution law and associativity of $+$; in the fourth, the hypothesis that $a$ is nilpotent and the definition of $n_{0}$.}
\begin{align*}
(1 - a) b
=
(1 - a) (1 + a + \ldots + a^{n_{0} - 1})
=
1 - a + a - \ldots - a^{n_{0} - 1} + a^{n_{0} - 1} - a^{n_{0}}
=
1 - a^{n_{0}}
=
1
\end{align*}
By hypothesis, $R$ is commutative, so $b (1 - a) = 1$ as well. Hence $1 - a \in R^{\times}$, as desired.

Remarks.
\begin{enumerate}
\item In part \ref{itm : e01q1a} we assumed that $a \neq 0$. However, our definition of $n_{0}$ there is valid for $a = 0$ as well, as is the argument here.
\item In fact, we don't need to take $n_{0}$, the minimum positive integer $n$ such that $a^{n} = 0$. Any such $n$ works for this argument.
\end{enumerate}}% End solution.



\section{Exercise \ref{sec : e01q2}}
\label{sec : e01q2}

(4 pt) Let $R$ be an integral domain. Prove that if $R$ is a euclidean domain, then $R$ is a principal ideal domain. (Heart points: Give---without proof---an example of a principal ideal domain that is not a euclidean domain.)

\spaceSolution{6in}{% Begin solution.
Remark. The key idea in this proof is that, in a euclidean domain, any nonzero ideal is generated by a nonzero element of minimal norm. The key tool is the division algorithm.

Let $R$ be a euclidean domain, and let $I \idealeq R$ be an ideal. Case 1: $I = (0)$. Then $I$ is principal, and we are done. Case 2: $I \neq (0)$. Then there exist nonzero elements of $I$. Let $b$ be a nonzero element of $I$ of minimal norm.% Begin footnote.
\footnote{This minimum exists by well ordering of $\Z$: By definition, the image of a norm map is a nonempty subset of $\integersNonnegative$.} % End footnote.
We claim that $I = (b)$. To see this, let $a \in I$ be arbitrary. By hypothesis, $R$ is a euclidean domain, so there exists a norm $N$ on $R$ with respect to which $R$ has a division algorithm. In particular, $b \neq 0$ by definition, so there exist $q, r \in R$ such that
\begin{align}
a
=
b q + r%
\label{eq : e01q2da}
\end{align}
with $r = 0$ or $N(r) < N(b)$. Suppose for the sake of contradiction that $r \neq 0$. Then the conclusion of the division algorithm implies that $N(r) < N(b)$. By the axioms of an ideal, $r = a - b q \in I$, so $r$ is a nonzero element of $I$ of smaller norm than $b$, contradicting the definition of $b$. Thus $r = 0$, so equation \eqref{eq : e01q2da} becomes $a = b q$, and thus $a \in (b)$, as desired. This shows that $I \subseteq (b)$.

The reverse inclusion follows immediately from the definition of an ideal: $b \in I$ if and only if $(b) \subseteq (I) = I$. Hence $I = (b)$, as desired.

The ring $\Z[(1 + \sqrt{-19}) / 2]$ is a principal ideal domain but not a euclidean domain.% Begin footnote.
\footnote{See Expositional Homework 01.}% End footnote.
}% End solution.



\section{Exercise \ref{sec : e01q3}}
\label{sec : e01q3}

(4 pt) For each of the following polynomials, state whether it is reducible or irreducible in the indicated polynomial ring. Justify your assertions.
\begin{align*}
f_{1} &= t^{2} + 2 \in \F_{7}[t]
&
f_{3} &= 6 t^{4} + 24 t^{3} + 18 t + 81 \in \Q[t]
\\
%f_{2} &= 4 t^{3} - t^{2} + 5 t - 6 \in \Q[t]
f_{2} &= 4 t^{3} + 9 t^{2} + 7 t - 12 \in \Z[t]
&
f_{4} &= t^{4} - 42 t^{2} + 30 t + 12 \in \Q[t]
\end{align*}

\spaceSolution{6in}{% Begin solution.
Remark. One of the beautiful aspects of mathematics is that there are different ways to prove a given statement. Try realizing this beauty here.

\paragraph{Analysis of $f_{1}$.}

Because $\deg f_{1} = 2$, $f_{1}$ is reducible if and only if the polynomial $f_{1} \in \F_{7}[t]$ has a factor of degree $1$, if and only if the function $f_{1} : \F_{7} \rightarrow \F_{7}$ has a zero. We compute
\begin{align*}
f_{1}(\pm{}3)
&=
-3
&
f_{1}(\pm{}2)
&=
-1
&
f_{1}(\pm{}1)
&=
3
&
f_{1}(0)
&=
2
\end{align*}
none of which are $0$. Thus $f_{1}$ is irreducible in $\F_{7}[t]$.

\paragraph{Analysis of $f_{2}$.}

One approach is to view $f_{2} \in \Q[t]$. Then, because $\deg f_{2} = 3$, the polynomial $f_{2} \in \Q[t]$ is reducible if and only if the function $f_{2} : \Q \rightarrow \Q$ has a zero.% Begin footnote.
\footnote{Why does this logic not work for $f_{2} \in \Z[t]$?} % End footnote.
By the rational zeros theorem, we know that if $\frac{a}{b}$ is a zero of $f_{2}$, then $a$ divides the constant term of $f_{2}$ and $b$ divides the leading coefficient of $f_{2}$.% Begin footnote.
\footnote{succinctly, $a \divides f_{2}(0)$ and $b \divides \LC(f_{2})$.} % End footnote.
Thus,
\begin{align*}
a
&\in
\{\pm{}1, \pm{}2, \pm{}3, \pm{4}, \pm{6}, \pm{}12\}
&
b
&\in
\{\pm{}1, \pm{}2, \pm{}4\}
\end{align*}
If we just look at the number of elements in each set, then we estimate $(2 \cdot 6) \cdot (2 \cdot 3) = 72$ possible values for $\frac{a}{b}$. We can reduce this number by half, by observing that only the sign of the ``combined'' fraction $\frac{a}{b}$, not the signs of $a$ and $b$ separately, matter. We can reduce the number a little more by omitting repeated values (for example, $\frac{1}{1} = \frac{2}{2} = \frac{4}{4}$). This leaves about thirty possible values for $\frac{a}{b}$---quick for a computer, too many for me. Can we do even better?

We can reduce this number significantly by viewing $f_{2} \in \R[t]$. Note that
\begin{align*}
f_{2}(0)
&=
-12
<
0
&
f_{2}(1)
&=
8
>
0
\end{align*}
Because polynomials with real coefficients define continuous functions $\R \rightarrow \R$, the intermediate value theorem implies that $f_{2}$ has a zero in the interval $(0,1)$. Assuming this is the only interval on which $f_{2}$ has real zeros (see Remark 2.2 below), this leaves only three values of $\frac{a}{b}$ consistent with the divisibility conditions, namely, $\frac{1}{4}, \frac{1}{2}, \frac{3}{4}$.

If we're willing to invest a little more work up front, we can do even better. We compute
\begin{align*}
f_{2}\left(\frac{1}{2}\right)
&=
4 \cdot \frac{1}{8} + 9 \cdot \frac{1}{4} + 7 \cdot \frac{1}{2} - 12
<
1 + 3 + 4 - 12
=
-4
<
0
\end{align*}
so the zero of $f_{2}$ must be in the interval $(\frac{1}{2}, 1)$. This implies that the only possible rational zero of $f_{2}$ is $\frac{3}{4}$. We compute
\begin{align*}
f_{2}\left(\frac{3}{4}\right)
=
\frac{27}{16} + \frac{81}{16} + \frac{84}{16} - \frac{14^{2} - 2^{2}}{16}
=
0
\end{align*}
Thus $f_{2}$ is reducible in $\Q[t]$.

We're not done yet---the exercise asks us whether $f_{2}$ is reducible in $\Z[t]$. Gau\ss{}'s lemma states that if $f_{2}$ is reducible in $\Q[t]$, then it's reducible in $\Q[t]$. OK, now we're done. For fun, let's see how Gau\ss{}'s lemma unfolds in this concrete example. We found that $\frac{3}{4}$ is a (rational) zero of $f_{2}$, or equivalently, that $t - \frac{3}{4}$ is a factor of $f_{2}$ in $\Q[t]$. The explicit factorization (which we can get from polynomial division) is
\begin{align*}
f_{2}
=
\left(t - \frac{3}{4}\right) \left(4 t^{2} + 12 t + 16\right)
\end{align*}
Gau\ss{}'s lemma appears as the fact that we can take a constant factor out of the second polynomial and distribute it through the first in such a way that both polynomials end up in $\Z[t]$. Here, that constant factor is $4$, and the result is
\begin{align*}
f_{2}
=
(4 t - 3) (t^{2} + 3 t + 4)
\end{align*}
witnessing the claim that $f_{2}$ is reducible in $\Z[t]$.

Remark 2.1. Because $f_{2}$ is reducible (although we don't know this, a priori), if we reduce $f_{2}$ modulo any prime $p \in \Z$ that does not divide the leading coefficient (why do we make this restriction?), then we'll find that the residue $\overline{f}_{2} \in (\Z / (p))[t]$ is reducible (that is, factors into two or more factors of positive degree). If we reduce modulo a few primes and find that $\overline{f}_{2}$ always factors, then we might suspect (though not be guaranteed!---remember the example from class) that these factorizations are ``shadows'' of an ``original factorization'' of $f_{2}$.

Moreover, if so, then the ``shadow'' factorizations provide clues about the factorization of $f_{2}$. Consider reducing $f_{2}$ modulo the first few ``valid'' primes:% Begin footnote.
\footnote{A priori, we don't know with which factors to put negative signs, if there are any. Note that this matters (why?).}% End footnote.
\begin{align*}
\Z / (3)
:
\overline{f}_{2}
&=
t^{3} + t
=
t (t^{2} + 1)
\\
\Z / (5)
:
\overline{f}_{2}
&=
-t^{3} - t^{2} + 2 t - 2
=
(-t + 2) (t^{2} - 2 t - 1)
\\
\Z / (7)
:
\overline{f}_{2}
&=
-3 t^{3} + 2 t^{2} + 2
=
(-3 t - 3) (t^{2} + 3 t - 3)
\end{align*}
From these data, we might conjecture that $f_{2} \in \Z[t]$ factors into a factor of degree $1$ (necessarily irreducible) and an irreducible factor of degree $2$; and that the factor of degree $1$, denote it $b t + a$, satisfies the relations
\begin{align*}
b
\equiv
1
\mod 3,
b
\equiv
-1
\mod 5,
b
\equiv
-3
\mod 7
\qquad
a
\equiv
0
\mod 3,
a
\equiv
2
\mod 5,
a
\equiv
-3
\mod 7
\end{align*}
From these equivalences, we might conjecture that $b = 4$ and $a = -3$.% Begin footnote.
\footnote{Claim: If we use primes $p$ that are large enough---for which we can give an upper bound of $p$ such that $\lfloor{}\frac{p}{2}\rfloor{}$ is greater than or equal to the largest coefficient of the original polynomial in $\Z[t]$---then the representatives stabilize to the actual coefficients of the factors.} % End footnote.
We can then check whether $(4 t - 3) \divides f_{2}$ or, equivalently (why?), whether $f_{2}(\frac{3}{4}) = 0$.

Question: The reduction technique applies to all ideals, not just prime ideals, that do not contain the leading coefficient. So why do we restrict our preceding analysis to prime ideals?% Begin footnote.
\footnote{Hint: denominators.} % End footnote.
In fact, we don't have to restrict to prime ideals, but we do have to ignore certain nonprime ideals (which?). Before we know the value of $b$, we won't know which to ignore.

Remark 2.2. In fact, though our argument does not need it (why not?), we can prove this is so, invoking calculus one more time.% Begin footnote.
\footnote{Calculus in algebra? Why not?!} % End footnote.
Again viewing $f_{2}$ as a function $f_{2} : \R \rightarrow \R$, we compute its first derivative to be
\begin{align*}
f_{2}'(t)
=
12 t^{2} + 18 t + 7
\end{align*}
I claim this function is always positive. We can see this in various ways:
\begin{enumerate}
\item The discriminant of $f_{2}'$ is $18^{2} - 4 (12) (7) = 324 - 336 < 0$. Thus the function $f_{2}'$ has no real zeros. Because $f_{2}'$ is a polynomial, the function $f_{2}'$ is continuous. Because $f_{2}'(0) = 7 > 0$, it follows that for all $t \in \R$, $f_{2}'(t) > 0$.
\item Completing the square, we find
\begin{align*}
f_{2}'
=
12 \left(t^{2} + \frac{3}{2} t - \frac{9}{16}\right) + 7 + 12 \left(\frac{9}{16}\right)
=
12 \left(t + \frac{3}{4}\right)^{2} + \alpha
\end{align*}
where $\alpha = 7 + \frac{27}{4} = \frac{55}{4} > 0$. The exact value doesn't matter; what matters is that $\alpha > 0$. Because the square of any real number is nonnegative, it follows that for all $t \in \R$, $f_{2}'(t) > 0$.
\end{enumerate}
This says that $f_{2}$ is monotonically increasing. From the function's end behavior, we conclude that $f_{2}$ has exactly one real zero.

\paragraph{Analysis of $f_{3}$.}

Note that $\deg f_{3} = 4$, so checking for zeros of the function $f_{3}$ is not sufficient to determine irreducibility. Two irreducibility detectors that do apply to this situation are reduction modulo an ideal and its corollary, the Eisenstein--Sch\"{o}onemann criterion.

Using the Eistenstein--Sch\"{o}nemann criterion: View $f_{3} \in \Z[t]$. The only prime that divides the constant term of $f_{3}$ is $3$. Note that $3^{2}$ also divides the constant term, so we cannot apply the Eisenstein--Sch\"{o}nemann criterion directly to $f_{3}$. However, recall% Begin footnote.
\footnote{See Expositional Homework 03, from DF3e, Exercise 9.5.16, p 312.} % End footnote.
that a polynomial with nonzero constant term is irreducible if and only if its reverse is irreducible. The reverse of $f_{3}$ is
\begin{align*}
\reverse f_{3}
=
81 t^{4} + 18 t^{3} + 24 t + 6
\end{align*}
To this polynomial, we may apply the generalized statement of the Eisenstein--Sch\"{o}nemann criterion% Begin footnote.
\footnote{See Expositional Homework 03, from DF3e, Exercise 9.5.17, p 312.} % End footnote.
with $p = 2$: $p = 2$ does not divide the leading coefficient, it does divide all other coefficients, and $p^{2} = 4$ does not divide the constant term. Thus, by the criterion, $\reverse f_{3}$ is irreducible in $\Frac(\Z)[t] = \Q[t]$, which as we have noted is equivalent to the statement $f_{3}$ is irreducible in $\Q[t]$.

Using reduction modulo an ideal: View $f_{3} \in \Z[t]$. The reduction technique requires that we do not send the leading coefficient of the polynomial to zero, so the smallest prime we may use with $f_{3}$ is $p = 5$.% Begin footnote.
\footnote{What happens if we reduce the coefficients modulo $4$?} % End footnote.
Reducing the coefficients of $f_{3}$ modulo $5$, we get
\begin{align*}
\overline{f}_{3}
=
t^{4} - t^{3} - 2 t + 1
\end{align*}
The function associated to this polynomial has a zero (in fact, two):
\begin{align*}
\overline{f}_{3}(-1)
&=
1 + 1 + 2 + 1
\equiv
0
&
\overline{f}_{3}(2)
&=
16 - 8 - 4 + 1
\equiv
0
\end{align*}
This decides nothing. Remember the shadows principle: Under suitable hypotheses (for example, that the polynomial be nonconstant and monic), a factorization in $R[t]$ will appear as a factorization in $(R / I)[t]$ for every proper ideal $I \ideal R$. However, an irreducible polynomial in $R[t]$ may have reducible reductions in some (sometimes all!) nonzero quotients $(R / I)[t]$.

The next ideal we can try is $(7) \idealeq \Z$. In this case, we get
\begin{align*}
\overline{f}_{3}
=
-t^{4} + 3 t^{3} - 3 t - 3
\end{align*}
Evaluating the associated function $\overline{f}_{3}$ at the seven elements of $\Z / (7)$, we find that $\overline{f}_{3}$ has no zeros.% Begin footnote.
\footnote{In particular, you---or your favorite computing machine---should find
\begin{align*}
\overline{f}_{3}(-3)
&=
-2
&
\overline{f}_{3}(-2)
&=
-2
&
\overline{f}_{3}(-1)
&=
3
&
\overline{f}_{3}(0)
&=
-3
&
\overline{f}_{3}(1)
&=
3
&
\overline{f}_{3}(2)
&=
-1
&
\overline{f}_{3}(3)
&=
2
\end{align*}} % End footnote.
It remains to check that $\overline{f}_{3} \in \F_{7}[t]$ has no factors of degree $2$. To certify this, it suffices to check only the monic degree-$2$ polynomials (why?), of which there are $49$; and in fact, to check only the irreducible monic degree-$2$ polynomials (why?), of which there are $21$.% Begin footnote.
\footnote{In general, let $p \in \integersPositive$ be prime, and let $\F_{p}$ be the finite field with $p$ elements. The number of reducible monic polynomials of degree $2$ in $\F_{p}[t]$ equals the number of ways of choosing, with replacement, two elements from $p$ elements (why?), which equals ${p + 2 - 1 \choose 2} = \frac{(p + 1) p}{2}$. Alternatively, we can reason as follows: If a monic degree-$2$ polynomial in $\F_{p}[t]$ factors, then it has either two distinct zeros or two identical zeros. The number of possibilities in the first case is ${p \choose 2}$, and in the second case is $p$, so the total number is $\frac{p (p - 1)}{2} + p = \frac{(p + 1) p}{2}$.

To read more on these topics, see Math Stack Exchange posts \href{https://math.stackexchange.com/questions/1393337/number-of-irreducible-quadratic-polynomials-over-a-finite-field}{1393337} (irreducible polynomials over a finite field) and \href{https://math.stackexchange.com/questions/474741/formula-for-combinations-with-replacement}{474741} (intuition for combinations with replacement).} % End footnote.
This is more polynomial divisions than I'd want to perform by hand in a timed exam environment,% Begin footnote.
\footnote{Or any environment, really.} % End footnote.
so I'd briefly sketch this approach for the grader, then look for others.

\paragraph{Analysis of $f_{4}$.}

Note that $\deg f_{4} = 4$, so our introductory comments in our analysis of $f_{3}$ also apply here. The only primes that divide the constant term are $2$ and $3$. Both primes do not divide the leading coefficient and do divide all other coefficients. However, $2^{2}$ divides the constant term, so we cannot use $p = 2$. $3^{2}$ does not divide the constant term. Thus the Eisenstein--Sch\"{o}nemann criterion% Begin footnote.
\footnote{See DF3e, Proposition 9.13, p 309.} % End footnote.
with $p = 3$ implies that $f_{4}$ is irreducible in $\Z[t]$, and Gau\ss{}'s lemma% Begin footnote.
\footnote{See DF3e, Proposition 9.5, p 303.} % End footnote.
implies that $f_{4}$ is therefore irreducible in $\Q[t]$.}% End solution.



\section{Exercise \ref{sec : e01q4}}
\label{sec : e01q4}

(4 pt) Let $F$ be a field, let $\alpha \in F$, and let $t$ be an indeterminate. We may give $F[t]$ the structure of a ring, an $F[t]$-module, or a $\Z$-module. For each map below, state whether it is a ring homomorphism, an $F[t]$-module homomorphism, or a $\Z$-module homomorphism. Justify your assertions. \fontHint{A given map may satisfy several or none of these conditions. The characterization may depend on the value of $\alpha$.}
\begin{align*}
\varphi
:
F[t]
&\rightarrow
F[t]
&
\psi
:
F[t]
&\rightarrow
F[t]
\\
f(t)
&\mapsto
\alpha f(t)
&
f(t)
&\mapsto
f(\alpha)
\end{align*}

\spaceSolution{6in}{% Begin solution.
Recall that a $\Z$-module is equivalent to an abelian group, so a $\Z$-module homomorphism is equivalent to a homomorphism of abelian groups.% Begin footnote.
\footnote{See DF3e, p 339 and p 346 Example (4).} % End footnote.
By definition, given a ring $(R, +, \times)$, $(R, +)$ is an abelian group. In particular, we may view the polynomial ring $F[t]$ as an abelian group if we keep addition and ignore multiplication.

Let $f_{1}, f_{2} \in F[t]$. We compute
\begin{align*}
\varphi(f_{1} + f_{2})
=
\alpha (f_{1} + f_{2})
=
\alpha f_{1} + \alpha f_{2}
=
\varphi(f_{1}) + \varphi(f_{2})
\end{align*}
where in the second equality we use the left-distributive law in $F[t]$; and
\begin{align*}
\psi(f_{1} + f_{2})
=
(f_{1} + f_{2})(\alpha)
=
f_{1}(\alpha) + f_{2}(\alpha)
=
\psi(f_{1}) + \psi(f_{2})
\end{align*}
where in the second equality we use the definition of addition of functions (!). We conclude that both $\varphi$ and $\psi$ are $\Z$-module homomorphisms.

It remains to analyze how the maps treat multiplication: ``external'' scalar multiplication and ``internal'' ring multiplication. Note that the ``scalars'' in the $F[t]$-module $F[t]$ are polynomials in $F[t]$, and the scalar multiplication is defined by the multiplication in the ring $F[t]$. Let $f, g \in F[t]$.

For $\varphi$, we compute
\begin{align*}
\varphi(g f)
&=
\alpha (g f)
=
g \cdot (\alpha f)
=
g \varphi(f)
&
\varphi(g) \varphi(f)
&=
\alpha g \cdot \alpha f
=
\alpha^{2} g f
\end{align*}
We conclude that, for all $\alpha \in F$, $\varphi$ is an $F[t]$-module homomorphism. It is a ring homomorphism if and only
\begin{align*}
\alpha g f
=
\varphi(g f)
&=
\varphi(g) \varphi(f)
=
\alpha^{2} g f
&
&\Leftrightarrow
&
(\alpha^{2} - \alpha) g f
&=
0
&
&\Leftrightarrow
&
\alpha
&=
0 \text{ or } 1
\end{align*}
where in the final equivalence we use the fact that $F[t]$ is an integral domain (why?) to invoke the cancellation law. If our definition of a homomorphism of rings with a multiplicative identity requires that the map send the multiplicative identity in the domain to the multiplicative identity of the codomain, then $\varphi$ is a ring homomorphism if and only if $\alpha = 1$.

For $\psi$, we compute
\begin{align*}
\psi(g f)
&=
(g f)(\alpha)
=
g(\alpha) f(\alpha)
=
\psi(g) \psi(f)
&
g \psi(f)
=
g(t) f(\alpha)
\end{align*}
We conclude that, for all $\alpha \in F$, $\psi$ is a ring homomorphism.% Begin footnote.
\footnote{The map $\psi$---usually with its codomain taken to be $F$, not $F[t]$---is often called evaluation at $t = \alpha$.} % End footnote.
For all $\alpha \in F$, $\psi$ is not an $F[t]$-module homomorphism: It is an $F[t]$-module homomorphism if and only if, for all $g, f \in F[t]$,
\begin{align*}
g(\alpha) f(\alpha)
=
\psi(g f)
&=
g \psi(f)
=
g(t) f(\alpha)
&
&\Leftrightarrow
&
(g(t) - g(\alpha)) f(\alpha)
&=
0
\end{align*}
which holds if and only if the ring of coefficients is the zero ring, which by definition a field is not.}% End solution.



\section{Exercise \ref{sec : e01q5}}
\label{sec : e01q5}

(4 pt) Let $F$ be a field, let $G$ be a finite group, and let $V$ be a unital $F G$-module.
\begin{enumerate}[label=(\alph*)]
\item\label{itm : e01q5a} We have seen that $V$ affords a representation $\rho : G \rightarrow \GL(V)$. Given $g \in G$, define $\rho(g)$.
\item\label{itm : e01q5b} Prove that for each $g \in G$, $\rho(g) \in \GL(V)$.
\end{enumerate}

\spaceSolution{6in}{% Begin solution.
Part \ref{itm : e01q5a}: Given $g \in G$, we use the ring action on $V$---that is, the map $\cdot : F G \times V \rightarrow V$ that is part of the module axioms---to define the representation $\rho$. Specifically, for each $g \in G$,
\begin{align*}
\rho(g)
:
V
&\rightarrow
V
\\
v
&\mapsto
(1_{F} g) \cdot v
\end{align*}

Part \ref{itm : e01q5b}: We verify two properties:
\begin{enumerate}[label=(\roman*)]
\item For each $g \in G$, the map $\rho(g)$ is linear.
\item For each $g \in G$, the map $\rho(g)$ is invertible.
\end{enumerate}

(i) $\rho(g)$ is linear. Let $\alpha \in F$; let $v_{1}, v_{2} \in V$; and let $g_{0} \in G$ denote the identity element of the group $G$. Note that for each $v \in V$, the element $(\alpha g_{0}) \cdot v$ in $V$, viewed as an $F G$-module, is the same element as $\alpha \cdot v$ in $V$, viewed as an $F$-module (aka $F$-vector space).% Begin footnote.
\footnote{The ring action $\cdot : F G \times V \rightarrow V$ on $V$ as an $F G$-module is different from the scalar multiplication (aka field action) $\cdot : F \times V \rightarrow V$ on $V$ as an $F$-vector space. Because the two agree in a natural way, as we argue here, we will use the same symbol to denote both.} % End footnote.
We compute
\begin{align*}
\rho(g)(\alpha \cdot v_{1} + v_{2})
&=
(1_{F} g) \cdot (\alpha \cdot v_{1} + v_{2})
\\
&=
(1_{F} g) \cdot ((\alpha g_{0}) \cdot v_{1}) + (1_{F} g) \cdot v_{2}
\\
&=
((1_{F} g) (\alpha g_{0})) \cdot v_{1} + (1_{F} g) \cdot v_{2}
\\
&=
(\alpha g) \cdot v_{1} + (1_{F} g) \cdot v_{2}
\\
&=
(\alpha g_{0}) \cdot (1_{F} g) \cdot v_{1} + (1_{F} g) \cdot v_{2}
\\
&=
\alpha \cdot \rho(g)(v_{1}) + \rho(g)(v_{2})
\end{align*}
This shows that for all $g \in G$, $\rho(g) \in \Hom_{F}(V, V)$.

(ii) $\rho(g)$ is invertible. Let $g_{1}, g_{2} \in G$. For all $v \in V$,
\begin{align*}
\rho(g_{1} g_{2})(v)
&=
(1_{F} g_{1} g_{2}) \cdot v
\\
&=
(1_{F} g_{1}) \cdot (1_{F} g_{2}) \cdot v
\\
&=
\rho(g_{1})(\rho(g_{2})(v))
\\
&=
(\rho(g_{1}) \circ \rho(g_{2}))(v)
\end{align*}
This shows that $\rho$ is a group homomorphism. In particular, let $g \in G$ be arbitrary; if we let $g_{1} = g$ and $g_{2} = g^{-1}$, then for all $v \in V$,
\begin{align*}
(\rho(g) \circ \rho(g^{-1}))(v)
=
\rho(g g^{-1})(v)
=
\rho(g_{0})(v)
=
(1_{F} g_{0}) \cdot v
=
v
=
\Id_{V}(v)
\end{align*}
where $\Id_{V}$ denotes the identity map on $V$. Likewise, $\rho(g^{-1}) \circ \rho(g) = \Id_{V}$. Thus, as maps from $V$ to $V$, $\rho(g)$ and $\rho(g^{-1})$ are inverses. Combined with (i), this shows that for all $g \in G$, $\rho(g) \in \GL(V)$.}% End solution.